import os
import glob
from dotenv import load_dotenv
import weaviate
from weaviate.classes.init import Auth
from weaviate.classes.config import Configure, Property, DataType
from weaviate.classes.query import MetadataQuery
from langchain.schema import Document
from langchain_ollama import OllamaEmbeddings

# === Import splitter ‡∏à‡∏≤‡∏Å doc_chunk_edit2.py ===
try:
    from doc_chunk_edit2 import AcademicDocumentSplitter
except ImportError:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå doc_chunk_edit2.py ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™ AcademicDocumentSplitter")
    exit()

# --- ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ (Configuration) ---
load_dotenv()

WEAVIATE_API_KEY = os.getenv("WEAVIATE_API_KEY")
DATA_FOLDER = "E:/workspace/langchain-study/data" 
BASE_COLLECTION_NAME = "LangchainStudy"

# ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏• BGE ‡∏à‡∏≤‡∏Å Ollama ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
BGE_MODELS = [
    "bge-m3",
    "bge-large",
    "mxbai-embed-large",
    "snowflake-arctic-embed" 
]

def load_and_split_documents(folder_path: str) -> list[Document]:
    """
    ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏î‡πâ‡∏ß‡∏¢ AcademicDocumentSplitter ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    """
    print(f"\nüìÅ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå '{folder_path}'...")
    if not os.path.exists(folder_path):
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå '{folder_path}'")
        return []

    file_paths = glob.glob(os.path.join(folder_path, "*.txt"))
    all_langchain_docs = []
    
    splitter = AcademicDocumentSplitter(
        max_chunk_size=1000, 
        overlap_size=0,
        min_chunk_size=100,
        quality_threshold=0.3
    )

    for file_path in file_paths:
        try:
            filename = os.path.basename(file_path)
            content = splitter.read_file(file_path)
            
            if not content:
                print(f"  - ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå: {filename}")
                continue

            chunk_dictionaries = splitter.split_document(content, source_file=filename)

            temp_docs = []
            for chunk_dict in chunk_dictionaries:
                page_content = chunk_dict.pop('content', '') 
                metadata = chunk_dict 
                new_doc = Document(page_content=page_content, metadata=metadata)
                temp_docs.append(new_doc)

            all_langchain_docs.extend(temp_docs)
            print(f"  - ‡πÑ‡∏ü‡∏•‡πå '{filename}' ‡∏ñ‡∏π‡∏Å‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô {len(temp_docs)} chunks")
            
        except Exception as e:
            print(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏ö‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå {os.path.basename(file_path)}: {e}")

    print(f"‚úÖ ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô, ‡πÑ‡∏î‡πâ chunks ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(all_langchain_docs)} ‡∏ä‡∏¥‡πâ‡∏ô")
    return all_langchain_docs


def create_hybrid_collection(client: weaviate.WeaviateClient, collection_name: str, vector_dim: int = 1024):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á Collection ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Hybrid Search (Dense Vector + BM25 Sparse)
    """
    if client.collections.exists(collection_name):
        print(f"‡∏û‡∏ö Collection ‡πÄ‡∏Å‡πà‡∏≤ '{collection_name}', ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏ö...")
        client.collections.delete(collection_name)
    
    print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Collection '{collection_name}' ‡πÅ‡∏ö‡∏ö Hybrid Search...")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Collection ‡∏û‡∏£‡πâ‡∏≠‡∏° BM25 configuration
    client.collections.create(
        name=collection_name,
        vectorizer_config=None,  # ‡πÉ‡∏ä‡πâ vector ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏á
        properties=[
            Property(name="text", data_type=DataType.TEXT),
            Property(name="source_file", data_type=DataType.TEXT),
            Property(name="main_topics", data_type=DataType.TEXT_ARRAY),  # ‡πÄ‡∏û‡∏¥‡πà‡∏° main_topics
        ],
        # ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô BM25 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö keyword search
        inverted_index_config=Configure.inverted_index(
            bm25_b=0.75,
            bm25_k1=1.2
        )
    )
    print("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Collection ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Dense Vector + BM25)")


def ingest_documents_with_embeddings(
    client: weaviate.WeaviateClient, 
    collection_name: str, 
    documents: list[Document],
    embeddings_model: OllamaEmbeddings
):
    """
    ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° embeddings ‡πÄ‡∏Ç‡πâ‡∏≤ Weaviate
    """
    print(f"\nüì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥ Embedding ‡πÅ‡∏•‡∏∞ Ingest ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(documents)} chunks...")
    
    collection = client.collections.get(collection_name)
    
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏≤‡∏£ embed ‡πÄ‡∏õ‡πá‡∏ô batch ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
    batch_size = 50
    for i in range(0, len(documents), batch_size):
        batch_docs = documents[i:i+batch_size]
        texts = [doc.page_content for doc in batch_docs]
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÅ‡∏ö‡∏ö batch
        print(f"  - ‡∏Å‡∏≥‡∏•‡∏±‡∏á embed batch {i//batch_size + 1}/{(len(documents)-1)//batch_size + 1}...")
        vectors = embeddings_model.embed_documents(texts)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤ Weaviate ‡∏û‡∏£‡πâ‡∏≠‡∏° vector
        with collection.batch.dynamic() as batch:
            for doc, vector in zip(batch_docs, vectors):
                # ‡∏î‡∏∂‡∏á main_topics ‡∏à‡∏≤‡∏Å metadata (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
                main_topics = doc.metadata.get('main_topics', [])
                # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô string ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô list
                if isinstance(main_topics, str):
                    main_topics = [main_topics] if main_topics else []
                
                batch.add_object(
                    properties={
                        "text": doc.page_content,
                        "source_file": doc.metadata.get('source_file', 'N/A'),
                        "main_topics": main_topics,  # ‡πÄ‡∏û‡∏¥‡πà‡∏° main_topics
                    },
                    vector=vector
                )
    
    print("‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ñ‡∏π‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤ Weaviate ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")


def hybrid_search(
    client: weaviate.WeaviateClient,
    collection_name: str,
    query: str,
    embeddings_model: OllamaEmbeddings,
    alpha: float = 0.5,
    limit: int = 3
):
    """
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö Hybrid (Dense + Sparse)
    
    Args:
        alpha: 0.0 = pure BM25, 1.0 = pure vector, 0.5 = balanced hybrid
    """
    collection = client.collections.get(collection_name)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á query vector
    print(f"  üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á query embedding...")
    query_vector = embeddings_model.embed_query(query)
    
    # ‡∏ó‡∏≥ Hybrid Search
    print(f"  üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö Hybrid (alpha={alpha})...")
    response = collection.query.hybrid(
        query=query,
        vector=query_vector,
        alpha=alpha,  # 0.5 = ‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á vector ‡πÅ‡∏•‡∏∞ keyword
        limit=limit,
        return_metadata=MetadataQuery(score=True, explain_score=True)
    )
    
    return response.objects


def run_test_for_model(client: weaviate.WeaviateClient, model_name: str, documents: list[Document]):
    if not documents:
        print("‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•, ‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ")
        return

    collection_name = f"{BASE_COLLECTION_NAME}_{model_name.replace('-', '_').replace('.', '_')}"
    print(f"\n{'='*70}")
    print(f"üß™ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_name}")
    print(f"üì¶ Collection: {collection_name}")
    print(f"{'='*70}")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings model
    embeddings = OllamaEmbeddings(model=model_name)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Collection ‡πÅ‡∏ö‡∏ö Hybrid
    create_hybrid_collection(client, collection_name)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° embeddings
    ingest_documents_with_embeddings(client, collection_name, documents, embeddings)
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
    query = "‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ù‡∏∏‡πà‡∏ô PM2.5 ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£"
    print(f"\n{'='*70}")
    print(f"üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Hybrid Search: \"{query}\"")
    print(f"{'='*70}")
    
    try:
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö 3 ‡πÅ‡∏ö‡∏ö
        test_configs = [
            (0.0, "Pure BM25 (Keyword Only)"),
            (0.5, "Hybrid (Balanced)"),
            (1.0, "Pure Vector (Semantic Only)")
        ]
        
        for alpha, description in test_configs:
            print(f"\n\nüìä {description} (alpha={alpha})")
            print("‚îÄ" * 70)
            
            results = hybrid_search(client, collection_name, query, embeddings, alpha=alpha, limit=3)
            
            if not results:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")
                continue
            
            for i, obj in enumerate(results, 1):
                props = obj.properties
                score = obj.metadata.score if obj.metadata.score else 0
                explain = obj.metadata.explain_score if hasattr(obj.metadata, 'explain_score') else None
                
                print(f"\n  [{i}] üìÑ ‡πÑ‡∏ü‡∏•‡πå: {props.get('source_file', 'N/A')}")
                print(f"      ‚ú® Hybrid Score: {score:.4f}")
                
                # ‡πÅ‡∏™‡∏î‡∏á explain_score ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
                if explain:
                    print(f"      üî¨ Score Explain: {explain}")
                
                print(f"      üè∑Ô∏è  Topics: {', '.join(props.get('main_topics', [])) or 'N/A'}")
                print(f"      üìñ ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {props.get('text', '')[:200].replace(os.linesep, ' ')}...")
        
        print("\n" + "="*70)
        
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {e}")
        import traceback
        traceback.print_exc()


def main():
    weaviate_client = None
    try:
        weaviate_client = weaviate.connect_to_local(
            host="localhost",
            port=8080,
            grpc_port=50051,
            auth_credentials=Auth.api_key(WEAVIATE_API_KEY)
        )
        if not weaviate_client.is_ready():
            raise ConnectionError("Weaviate is not ready.")
        print("‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Weaviate ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Weaviate ‡πÑ‡∏î‡πâ! : {e}")
        exit()

    try:
        documents = load_and_split_documents(DATA_FOLDER)
        if not documents:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
            return

        while True:
            print(f"\n{'='*70}")
            print("üöÄ ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö Hybrid Search (Dense Vector + BM25 Sparse)")
            print(f"{'='*70}")
            for i, model in enumerate(BGE_MODELS):
                print(f"  [{i+1}] ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model}")
            print("  [0] ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
            print("="*70)
            
            try:
                choice_input = input("\n‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç): ").strip()
                
                if not choice_input:
                    print("‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡πâ‡∏≠‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç")
                    continue
                    
                choice = int(choice_input)
                
                if choice == 0:
                    print("üëã ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
                    break
                elif 1 <= choice <= len(BGE_MODELS):
                    selected_model = BGE_MODELS[choice - 1]
                    run_test_for_model(weaviate_client, selected_model, documents)
                else:
                    print("‚ùå ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î")
            except ValueError:
                print("‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡πâ‡∏≠‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
            except KeyboardInterrupt:
                print("\n\nüëã ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° (Ctrl+C)")
                break
    finally:
        if weaviate_client:
            weaviate_client.close()
            print("\nüîå ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Weaviate ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")


if __name__ == "__main__":
    main()